packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(SnowballC)
library(wordnet)
library(ggplot2)
library(sentimentr)
library(qdap)
library(NLP)
library(openNLP)
library(topicmodels)
library(syuzhet)
library(beeswarm)
library(factoextra)
library(cluster)
library(fpc)
folder.path="../data/InauguralSpeeches/"
speech.list=list.files(path=folder.path,pattern = "*.txt")
prez.out=substr(speech.list, 6, nchar(speech.list)-4)
ff.all <- Corpus(DirSource(folder.path))
ff.all <- tm_map(ff.all,stripWhitespace)
ff.all <- tm_map(ff.all,content_transformer(tolower))
#set up stop words
myStopwords <- c("can","say","one","way","use","also","howev","tell","will","much","need","take","tend","even","like","particular","rather","said","get","well","make","ask","come","end","first","two","help","often","may","might","see","someth","thing","point","post","look","right","now","think","'ve","'re","anoth","put","set","new","good","want","sure","kind","larg","yes","day","quit","sinc","attempt","lack","seen","awar","littl","ever","moreov","though","found","abl","enough","far","earli","away","achiev","last","never","brief","bit","entir","brief","great","lot")
ff.all <- tm_map(ff.all,removeWords,stopwords("english"))
ff.all <- tm_map(ff.all,removeWords,myStopwords)
ff.all <- tm_map(ff.all,stemDocument)
ff.all <- tm_map(ff.all,removeWords,character(0))###
ff.all <- tm_map(ff.all,removePunctuation)
ff.all <- tm_map(ff.all,removeNumbers)
ff.all <- tm_map(ff.all,PlainTextDocument)
dates<- read.table("C:/Users/ZISHUO LI/Documents/R/data/InauguationDates.txt",header = T,sep="\t")
for( i in 1:ncol(dates)){dates[,i]<- dates[,i] %>% as.character()}  # turn factor into character
choose_year <- function(x){substr(x,nchar(x)-3,nchar(x))} #set a function to choose year rather than day/month/year
year_data<- sapply(dates[,2:5],choose_year)
# select white space and . and replace with"" to have the same format with prez.out
test<- gregexpr("\\s|[[:punct:]]",dates$PRESIDENT)
regmatches(dates$PRESIDENT,test) <- ""
dates <- cbind(dates[,1],year_data) %>%data.frame()
for(i in 2:5){dates[,i] <- as.numeric(as.character(dates[,i]))}
dates[,1] <- dates[,1]%>% as.character()
dates[dates[,1]=="GroverCleveland",1]<-c("GroverCleveland-I","GroverCleveland-II")
# set a function to select president, corresponding year, and term.
dates_function <- function(x){
term_value<- sum(!is.na(x[,2:5]))
answer <- NULL
for(i in 1:term_value){
answer1 <- c(x[,1],term=i,x[,1+i])
answer <- rbind(answer,answer1)
}
return(answer)
}
# use the function above to selecet data
answer <- NULL
for(i in 1:dim(dates)[1]){
answer <- rbind(answer,dates_function(dates[i,]))
}
colnames(answer) <- c("File","term","year")
answer <- data.frame(answer)
for(i in 2:3){
answer[,i] <- as.numeric(as.character(answer[,i]))}
index<- which(is.na(answer[,3])) #since president GroverCleverland is so special, I decide to deal with it manually.
answer[index,3] <- dates[dates[,1]=="GroverCleveland-II",3]
answer[index,2] <- 2
colnames(answer) <- c("File",colnames(answer)[2:3])
dates_prez <- answer
# set a function to select president, corresponding year, and term.
dates_function <- function(x){
term_value<- sum(!is.na(x[,2:5]))
answer <- NULL
for(i in 1:term_value){
answer1 <- c(x[,1],term=i,x[,1+i])
answer <- rbind(answer,answer1)
}
return(answer)
}
# use the function above to selecet data
answer <- NULL
for(i in 1:dim(dates)[1]){
answer <- rbind(answer,dates_function(dates[i,]))
}
colnames(answer) <- c("File","term","year")
answer <- data.frame(answer)
for(i in 2:3){
answer[,i] <- as.numeric(as.character(answer[,i]))}
index<- which(is.na(answer[,3])) #since president GroverCleverland is so special, I decide to deal with it manually.
answer[index,3] <- dates[dates[,1]=="GroverCleveland-II",3]
answer[index,2] <- 2
colnames(answer) <- c("File",colnames(answer)[2:3])
dates_prez <- answer
dates<- read.table(""../data/InauguationDates.txt",header = T,sep="\t")
dates<- read.table("../data/InauguationDates.txt",header = T,sep="\t")
?readLines
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(SnowballC)
library(wordnet)
library(ggplot2)
library(sentimentr)
library(qdap)
library(NLP)
library(openNLP)
library(topicmodels)
library(syuzhet)
library(beeswarm)
library(factoextra)
library(cluster)
library(fpc)
folder.path="../data/InauguralSpeeches/"
speech.list=list.files(path=folder.path,pattern = "*.txt")
prez.out=substr(speech.list, 6, nchar(speech.list)-4)
ff.all <- Corpus(DirSource(folder.path))
ff.all <- tm_map(ff.all,stripWhitespace)
ff.all <- tm_map(ff.all,content_transformer(tolower))
#set up stop words
myStopwords <- c("can","say","one","way","use","also","howev","tell","will","much","need","take","tend","even","like","particular","rather","said","get","well","make","ask","come","end","first","two","help","often","may","might","see","someth","thing","point","post","look","right","now","think","'ve","'re","anoth","put","set","new","good","want","sure","kind","larg","yes","day","quit","sinc","attempt","lack","seen","awar","littl","ever","moreov","though","found","abl","enough","far","earli","away","achiev","last","never","brief","bit","entir","brief","great","lot")
ff.all <- tm_map(ff.all,removeWords,stopwords("english"))
ff.all <- tm_map(ff.all,removeWords,myStopwords)
ff.all <- tm_map(ff.all,stemDocument)
ff.all <- tm_map(ff.all,removeWords,character(0))###
ff.all <- tm_map(ff.all,removePunctuation)
ff.all <- tm_map(ff.all,removeNumbers)
ff.all <- tm_map(ff.all,PlainTextDocument)
dates<- read.table("../data/InauguationDates.txt",header = T,sep="\t")
for( i in 1:ncol(dates)){dates[,i]<- dates[,i] %>% as.character()}  # turn factor into character
choose_year <- function(x){substr(x,nchar(x)-3,nchar(x))} #set a function to choose year rather than day/month/year
year_data<- sapply(dates[,2:5],choose_year)
# select white space and . and replace with"" to have the same format with prez.out
test<- gregexpr("\\s|[[:punct:]]",dates$PRESIDENT)
regmatches(dates$PRESIDENT,test) <- ""
dates <- cbind(dates[,1],year_data) %>%data.frame()
for(i in 2:5){dates[,i] <- as.numeric(as.character(dates[,i]))}
dates[,1] <- dates[,1]%>% as.character()
dates[dates[,1]=="GroverCleveland",1]<-c("GroverCleveland-I","GroverCleveland-II")
dtm <- DocumentTermMatrix(ff.all)
freq <- colSums(as.matrix(dtm))
ord <- order(freq,decreasing = T)
row.names(dtm) <- speech.list
rowTotals <- apply(dtm,1,sum)
burnin <- 4000
iter <- 2000
thin <- 500
seed <- 2003
nstart <- 5
best <- TRUE
k <- 15
ldaout <- LDA(dtm,k,method = "Gibbs",control=list(seed=seed,best=best,burnin=burnin,iter=iter,thin=thin))
ldaout.topics <- as.matrix(topics(ldaout))
table(c(1:k,ldaout.topics))
topicProbabilities <- as.data.frame(ldaout@gamma)
terms.beta=ldaout@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaout@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms <- as.matrix(terms(ldaout,20))
ldaOut.terms
dtmss <- removeSparseTerms(dtm, 0.2)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=5)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=5, border="red")
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
freq <- sort(colSums(as.matrix(dtm)))
wf <- data.frame(word=names(freq),freq=freq)
freq2 <- colSums(as.matrix(dtm))
p <- ggplot(subset(tail(wf,20),freq>50),aes(word,freq))
p <- p+geom_bar(stat = "identity")
p <- p+theme(axis.text.x = element_text(angle = 45,hjust = 1,size = 10))
p
wordcloud(names(freq),freq,min.freq = 100)
wordcloud(names(freq),freq,min.freq = 100,scale = c(5,.1),colors=brewer.pal(6,"Dark2"))
speech.sentance<- lapply(speech.list, function(x)readLines(x))
sentence.list=NULL
for(i in 1:length(speech.sentance)){
sentences=sent_detect(speech.sentance[[i]],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
term =as.numeric(substr(prez.out[i],nchar(prez.out[i]),nchar(prez.out[i])))
File=as.character(substr(prez.out,1,nchar(prez.out)-2)[i])
sentence.list=rbind(sentence.list,
cbind(sentences=as.character(sentences),
File,
term,
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list<- data.frame(sentence.list)
sentence.list=sentence.list%>%filter(!is.na(word.count))
sentence.list <- data.frame(sentence.list)
name_inaug<- colnames(sentence.list)
sentence.list_part1 <- sentence.list[,1:2]
sentence.list_part2 <- NULL
for (k in 3:15){
sentence.list_part2 <- cbind(sentence.list_part2,as.numeric(as.character(sentence.list[,k])))
}
sentence.list <-cbind(sentence.list_part1,sentence.list_part2)
colnames(sentence.list) <- name_inaug
sentence.list<- merge(sentence.list,dates_prez,by.x = c("File","term"),by.y = c("File","term"))
colnames(sentence.list)<-c(colnames(sentence.list)[1:length(colnames(sentence.list))-1],"year")
?readLines
speech.sentance<- lapply(speech.list, function(x)readLines(x,folder.path="../data/InauguralSpeeches/"))
speech.sentance<- lapply(speech.list, function(x)readLines(x,path="../data/InauguralSpeeches/"))
speech.sentance<- lapply(speech.list, function(x)readLines(x,"../data/InauguralSpeeches/"))
speech.list
speech.sentance<- readLines(paste("../data/InauguralSpeeches/",speech.list)))
speech.sentance<- readLines(paste("../data/InauguralSpeeches/",speech.list))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x)))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x)))
readLines(paste("../data/InauguralSpeeches/",speech.list[1]))
readLines(paste("../data/InauguralSpeeches/",speech.list[1],sep = ""))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x,sep = "")))
sentence.list=NULL
for(i in 1:length(speech.sentance)){
sentences=sent_detect(speech.sentance[[i]],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x,sep = "")))
sentence.list=NULL
for(i in 1:length(speech.sentance)){
sentences=sent_detect(speech.sentance[[i]],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
term =as.numeric(substr(prez.out[i],nchar(prez.out[i]),nchar(prez.out[i])))
File=as.character(substr(prez.out,1,nchar(prez.out)-2)[i])
sentence.list=rbind(sentence.list,
cbind(sentences=as.character(sentences),
File,
term,
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list<- data.frame(sentence.list)
sentence.list=sentence.list%>%filter(!is.na(word.count))
sentence.list <- data.frame(sentence.list)
name_inaug<- colnames(sentence.list)
sentence.list_part1 <- sentence.list[,1:2]
sentence.list_part2 <- NULL
for (k in 3:15){
sentence.list_part2 <- cbind(sentence.list_part2,as.numeric(as.character(sentence.list[,k])))
}
sentence.list <-cbind(sentence.list_part1,sentence.list_part2)
colnames(sentence.list) <- name_inaug
sentence.list<- merge(sentence.list,dates_prez,by.x = c("File","term"),by.y = c("File","term"))
colnames(sentence.list)<-c(colnames(sentence.list)[1:length(colnames(sentence.list))-1],"year")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(SnowballC)
library(wordnet)
library(ggplot2)
library(sentimentr)
library(qdap)
library(NLP)
library(openNLP)
library(topicmodels)
library(syuzhet)
library(beeswarm)
library(factoextra)
library(cluster)
library(fpc)
folder.path="../data/InauguralSpeeches/"
speech.list=list.files(path=folder.path,pattern = "*.txt")
prez.out=substr(speech.list, 6, nchar(speech.list)-4)
ff.all <- Corpus(DirSource(folder.path))
ff.all <- tm_map(ff.all,stripWhitespace)
ff.all <- tm_map(ff.all,content_transformer(tolower))
#set up stop words
myStopwords <- c("can","say","one","way","use","also","howev","tell","will","much","need","take","tend","even","like","particular","rather","said","get","well","make","ask","come","end","first","two","help","often","may","might","see","someth","thing","point","post","look","right","now","think","'ve","'re","anoth","put","set","new","good","want","sure","kind","larg","yes","day","quit","sinc","attempt","lack","seen","awar","littl","ever","moreov","though","found","abl","enough","far","earli","away","achiev","last","never","brief","bit","entir","brief","great","lot")
ff.all <- tm_map(ff.all,removeWords,stopwords("english"))
ff.all <- tm_map(ff.all,removeWords,myStopwords)
ff.all <- tm_map(ff.all,stemDocument)
ff.all <- tm_map(ff.all,removeWords,character(0))###
ff.all <- tm_map(ff.all,removePunctuation)
ff.all <- tm_map(ff.all,removeNumbers)
ff.all <- tm_map(ff.all,PlainTextDocument)
dates<- read.table("../data/InauguationDates.txt",header = T,sep="\t")
for( i in 1:ncol(dates)){dates[,i]<- dates[,i] %>% as.character()}  # turn factor into character
choose_year <- function(x){substr(x,nchar(x)-3,nchar(x))} #set a function to choose year rather than day/month/year
year_data<- sapply(dates[,2:5],choose_year)
# select white space and . and replace with"" to have the same format with prez.out
test<- gregexpr("\\s|[[:punct:]]",dates$PRESIDENT)
regmatches(dates$PRESIDENT,test) <- ""
dates <- cbind(dates[,1],year_data) %>%data.frame()
for(i in 2:5){dates[,i] <- as.numeric(as.character(dates[,i]))}
dates[,1] <- dates[,1]%>% as.character()
dates[dates[,1]=="GroverCleveland",1]<-c("GroverCleveland-I","GroverCleveland-II")
# set a function to select president, corresponding year, and term.
dates_function <- function(x){
term_value<- sum(!is.na(x[,2:5]))
answer <- NULL
for(i in 1:term_value){
answer1 <- c(x[,1],term=i,x[,1+i])
answer <- rbind(answer,answer1)
}
return(answer)
}
# use the function above to selecet data
answer <- NULL
for(i in 1:dim(dates)[1]){
answer <- rbind(answer,dates_function(dates[i,]))
}
colnames(answer) <- c("File","term","year")
answer <- data.frame(answer)
for(i in 2:3){
answer[,i] <- as.numeric(as.character(answer[,i]))}
index<- which(is.na(answer[,3])) #since president GroverCleverland is so special, I decide to deal with it manually.
answer[index,3] <- dates[dates[,1]=="GroverCleveland-II",3]
answer[index,2] <- 2
colnames(answer) <- c("File",colnames(answer)[2:3])
dates_prez <- answer
head(dates_prez)
dtmss <- removeSparseTerms(dtm, 0.2)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=5)   # "k=" defines the number of clusters you are using
rect.hclust(fit, k=5, border="red")
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 3)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
freq <- sort(colSums(as.matrix(dtm)))
wf <- data.frame(word=names(freq),freq=freq)
freq2 <- colSums(as.matrix(dtm))
p <- ggplot(subset(tail(wf,20),freq>50),aes(word,freq))
p <- p+geom_bar(stat = "identity")
p <- p+theme(axis.text.x = element_text(angle = 45,hjust = 1,size = 10))
p
wordcloud(names(freq),freq,min.freq = 100)
wordcloud(names(freq),freq,min.freq = 100,scale = c(5,.1),colors=brewer.pal(6,"Dark2"))
speech.sentance<- lapply(speech.list, function(x)readLines(paste("../data/InauguralSpeeches/",x,sep = "")))
sentence.list=NULL
for(i in 1:length(speech.sentance)){
sentences=sent_detect(speech.sentance[[i]],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
term =as.numeric(substr(prez.out[i],nchar(prez.out[i]),nchar(prez.out[i])))
File=as.character(substr(prez.out,1,nchar(prez.out)-2)[i])
sentence.list=rbind(sentence.list,
cbind(sentences=as.character(sentences),
File,
term,
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list<- data.frame(sentence.list)
sentence.list=sentence.list%>%filter(!is.na(word.count))
sentence.list <- data.frame(sentence.list)
name_inaug<- colnames(sentence.list)
sentence.list_part1 <- sentence.list[,1:2]
sentence.list_part2 <- NULL
for (k in 3:15){
sentence.list_part2 <- cbind(sentence.list_part2,as.numeric(as.character(sentence.list[,k])))
}
sentence.list <-cbind(sentence.list_part1,sentence.list_part2)
colnames(sentence.list) <- name_inaug
sentence.list<- merge(sentence.list,dates_prez,by.x = c("File","term"),by.y = c("File","term"))
colnames(sentence.list)<-c(colnames(sentence.list)[1:length(colnames(sentence.list))-1],"year")
par(mfrow=c(2,2))
sentence_Donald<- filter(sentence.list,File=="DonaldJTrump")
d<- group_by(sentence.list,year)
timeline<- summarise(d,
totalwords=sum(word.count),
totalsentenca=length(sent.id)
)
ggplot(data =timeline )+
geom_line(mapping = aes(x=year,y=totalwords))
ggplot(data = timeline)+
geom_line(mapping = aes(x=year,y=totalsentenca))
# Check the shortest and longest sentences that donald trump said.
arrange(sentence_Donald,desc(word.count))[1:3,"sentences"]
arrange(sentence_Donald,word.count)[1:4,"sentences"]
f.plotsent.len=function(In.list, InFile, InTerm, President){
col.use=c("lightgray", "red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1",
"black", "darkgoldenrod2")
In.list$topemotion=apply(select(In.list,anger:positive),1, which.max)
In.list$topemotion.v=apply(select(In.list,anger:positive), 1, max)
In.list$topemotion[In.list$topemotion.v<0.05]=0
In.list$topemotion=In.list$topemotion+1
temp=In.list$topemotion.v
In.list$topemotion.v[temp<0.05]=1
df=In.list%>%filter(File==InFile,term==InTerm)%>%
select(sent.id, word.count, topemotion,topemotion.v)
ptcol.use=alpha(col.use[df$topemotion],sqrt(sqrt(df$topemotion.v)))
plot(df$sent.id, df$word.count,
col=ptcol.use,
type="h", #ylim=c(-10, max(In.list$word.count)),
main=President)
}
par(mfrow=c(3,1), mar=c(1,0,2,0), bty="n", xaxt="n", yaxt="n", font.main=1)
f.plotsent.len(In.list=sentence.list, InFile="DonaldJTrump",InTerm=1, President="Donald Trump")
f.plotsent.len(In.list=sentence.list, InFile="BarackObama",  InTerm=1, President="Barack Obama")
f.plotsent.len(In.list=sentence.list, InFile="GeorgeWBush", InTerm=1, President="George W. Bush")
print("Barack Obama")
speech.df=tbl_df(sentence.list)%>%
filter(File=="BarackObama", term==1, word.count>=5)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
print("Donald Trump")
speech.df=tbl_df(sentence.list)%>%
filter(File=="DonaldJTrump", term==1,word.count>=5)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
#The distribution of emotions in all sentences
par(mfrow=c(1,1))
emo.means=colMeans(select(sentence.list, anger:trust)>0.01)
barplot(height = emo.means[order(emo.means)],horiz = TRUE,col=1:8,main="Inaugural Speeches",names=names(emo.means),legend = names(emo.means),args.legend = list(x="bottomright",cex=1.2))
presid.summary=sentence.list%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust))
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1],iter.max=200,5)
fviz_cluster(km.res,stand=F, repel= TRUE,data = presid.summary[,-1], xlab="", xaxt="n",show.clust.cent=FALSE)
